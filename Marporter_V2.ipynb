{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "! pip install -Uq langchain_openai langchain langchain-community streamlit pypdf faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.11.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_experimental in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_experimental) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_experimental) (0.3.19)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.1.143)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.17.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.40.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (18.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, DataFrameLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import tempfile\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import pandas as pd\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "########## 1. í´ë” ë‚´ íŒŒì¼ ë¡œë“œ ##########\n",
    "\n",
    "# í´ë” ê²½ë¡œ ì„¤ì •\n",
    "folder_path = \"./data\"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "\n",
    "# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_pdf_with_metadata(file_path):\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load_and_split(text_splitter)\n",
    "    for doc in documents:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"page\"] = doc.metadata.get(\"page\", \"Unknown\")\n",
    "    return documents\n",
    "\n",
    "# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_excel_with_metadata(file_path):\n",
    "    documents = []\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "        sheet_docs = loader.load_and_split(text_splitter)\n",
    "        for doc in sheet_docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "            doc.metadata[\"sheet_name\"] = sheet_name\n",
    "            doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "        documents.extend(sheet_docs)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_with_metadata(file_path):\n",
    "    documents = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "    csv_docs = loader.load_and_split(text_splitter)\n",
    "    for doc in csv_docs:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "    documents.extend(csv_docs)\n",
    "    return documents\n",
    "\n",
    "# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            documents.extend(load_pdf_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
    "            documents.extend(load_excel_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".csv\"):\n",
    "            documents.extend(load_csv_with_metadata(file_path))\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜\n",
    "def chat_with_agent(user_input, agent_executor):\n",
    "    result = agent_executor({\"input\": user_input})\n",
    "    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬\n",
    "    return response\n",
    "\n",
    "# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in st.session_state.session_history:\n",
    "        st.session_state.session_history[session_ids] = ChatMessageHistory()\n",
    "    return st.session_state.session_history[session_ids]\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_messages():\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ\n",
    "all_docs = load_documents_from_folder(folder_path)\n",
    "\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±\n",
    "vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"csv_search\",\n",
    "    description=\"Use this tool to search information from the csv document\"\n",
    ")\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"AI ë¹„ì„œ\", layout=\"wide\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "    st.image('Marporter.png', width=1200)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ ëŒ€ë™ì´' ì…ë‹ˆë‹¤\")  # ì‹œì‘ íƒ€ì´í‹€\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    if \"session_history\" not in st.session_state:\n",
    "        st.session_state[\"session_history\"] = {}\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.session_state[\"OPENAI_API\"] = st.text_input(label=\"OPENAI API í‚¤\", placeholder=\"Enter Your API Key\", value=\"\", type=\"password\")\n",
    "        st.markdown('---')\n",
    "\n",
    "    # OpenAI API í‚¤ê°€ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    if st.session_state[\"OPENAI_API\"] :\n",
    "        os.environ['OPENAI_API_KEY'] = st.session_state[\"OPENAI_API\"]\n",
    "\n",
    "        # return retriever_tool\n",
    "        tools = [retriever_tool]\n",
    "\n",
    "        # LLM ì„¤ì •\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # Prompt ì •ì˜\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.\n",
    "                    You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.\n",
    "                    Our company is a farming machinery firm called 'ëŒ€ë™'. And Representative domestic competitors are 'TYM' and 'LSì— íŠ¸ë¡ '.\n",
    "                    Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.\n",
    "                    Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                    You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                    When the chat begins, you introduce yourself and ask the user for a keywords in [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥] to search.\n",
    "                    If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].\n",
    "                    Please answer questions following the format [FORMAT] below.\n",
    "                    \n",
    "                    'ê¸°ì‚¬ ì œëª©' is \n",
    "\n",
    "                    #FORMAT\n",
    "                    <ê¸°ì‚¬ ì œëª©>\n",
    "                    ì¼ì :  \n",
    "\n",
    "                    * ìš”ì•½\n",
    "                    -\n",
    "                    -\n",
    "                    -\n",
    "\n",
    "                    ì¶œì²˜ :              \n",
    "                        \"\"\"\n",
    "\n",
    "                ),\n",
    "                (\"placeholder\", \"{chat_history}\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„± (initialize_agent ëŒ€ì‹  create_tool_calling_agent ì‚¬ìš©)\n",
    "        agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "        # AgentExecutor ì •ì˜\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "        user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "        if user_input:\n",
    "            session_id = \"default_session\"\n",
    "            session_history = get_session_history(session_id)\n",
    "\n",
    "            if session_history.messages:\n",
    "                previous_messages = [{\"role\": msg['role'], \"content\": msg['content']} for msg in session_history.messages]\n",
    "                response = chat_with_agent(user_input + \"\\n\\nPrevious Messages: \" + str(previous_messages), agent_executor)\n",
    "            else:\n",
    "                response = chat_with_agent(user_input, agent_executor)\n",
    "\n",
    "            # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "            st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "            st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "            # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€\n",
    "            session_history.add_message({\"role\": \"user\", \"content\": user_input})\n",
    "            session_history.add_message({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "        print_messages()\n",
    "\n",
    "    else:\n",
    "        st.warning(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, DataFrameLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import tempfile\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import pandas as pd\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n",
    "########## 1. í´ë” ë‚´ íŒŒì¼ ë¡œë“œ ##########\n",
    "\n",
    "# í´ë” ê²½ë¡œ ì„¤ì •\n",
    "folder_path = \"./data\"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_pdf_with_metadata(file_path):\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load_and_split(text_splitter)\n",
    "    for doc in documents:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"page\"] = doc.metadata.get(\"page\", \"Unknown\")\n",
    "    return documents\n",
    "\n",
    "# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_excel_with_metadata(file_path):\n",
    "    documents = []\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "        sheet_docs = loader.load_and_split(text_splitter)\n",
    "        for doc in sheet_docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "            doc.metadata[\"sheet_name\"] = sheet_name\n",
    "            doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "        documents.extend(sheet_docs)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_with_metadata(file_path):\n",
    "    documents = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "    csv_docs = loader.load_and_split(text_splitter)\n",
    "    for doc in csv_docs:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "    documents.extend(csv_docs)\n",
    "    return documents\n",
    "\n",
    "# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            documents.extend(load_pdf_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
    "            documents.extend(load_excel_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".csv\"):\n",
    "            documents.extend(load_csv_with_metadata(file_path))\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜\n",
    "def chat_with_agent(user_input, agent_executor):\n",
    "    result = agent_executor({\"input\": user_input})\n",
    "    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬\n",
    "    return response\n",
    "\n",
    "# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in st.session_state.session_history:\n",
    "        st.session_state.session_history[session_ids] = ChatMessageHistory()\n",
    "    return st.session_state.session_history[session_ids]\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_messages():\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ\n",
    "all_docs = load_documents_from_folder(folder_path)\n",
    "\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±\n",
    "vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"csv_search\",\n",
    "    description=\"Use this tool to search information from the csv document\"\n",
    ")\n",
    "\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"ë§ˆí¬í„°\", layout=\"wide\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "    st.image('chatbot_image.png', width=600)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! ëŒ€ë™ ë§ˆí¬í„° ì…ë‹ˆë‹¤\")  # ì‹œì‘ íƒ€ì´í‹€\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    if \"session_history\" not in st.session_state:\n",
    "        st.session_state[\"session_history\"] = {}\n",
    "\n",
    "    # with st.sidebar:\n",
    "    #     st.session_state[\"OPENAI_API\"] = st.text_input(label=\"OPENAI API í‚¤\", placeholder=\"Enter Your API Key\", value=\"\", type=\"password\")\n",
    "    #     st.markdown('---')\n",
    "\n",
    "    # # OpenAI API í‚¤ê°€ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    # if st.session_state[\"OPENAI_API\"] :\n",
    "    #     os.environ['OPENAI_API_KEY'] = st.session_state[\"OPENAI_API\"]\n",
    "\n",
    "# return retriever_tool\n",
    "    tools = [retriever_tool]\n",
    "\n",
    "    # LLM ì„¤ì •\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # Prompt ì •ì˜\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"\n",
    "                You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.\n",
    "                Your name is `ë§ˆí¬í„°`.\n",
    "                You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.\n",
    "                Our company is a farming machinery firm called 'ëŒ€ë™'. and Representative domestic competitors include 'TYM' and 'LSì— íŠ¸ë¡ '.\n",
    "                Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.\n",
    "                Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                When the chatbot begins, you should introduce yourself and ask the user for a keywords to search.\n",
    "                If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].\n",
    "                Please answer questions following the format [FORMAT] below.\n",
    "                `ìš”ì•½` should include a condensed version of the article's content. \n",
    "                Include the title in the `ê¸°ì‚¬ ì œëª©` section.   \n",
    "                    \n",
    "\n",
    "                #FORMAT\n",
    "                [ê¸°ì‚¬ ì œëª©] \n",
    "                ì¼ì :  \n",
    "\n",
    "                * ìš”ì•½\n",
    "                -\n",
    "                -\n",
    "                -\n",
    "\n",
    "                ì¶œì²˜ :              \n",
    "                    \n",
    "                    \"\"\"\n",
    "\n",
    "            ),\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ì—ì´ì „íŠ¸ ìƒì„± (initialize_agent ëŒ€ì‹  create_tool_calling_agent ì‚¬ìš©)\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "    # AgentExecutor ì •ì˜\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "    if user_input:\n",
    "        session_id = \"default_session\"\n",
    "        session_history = get_session_history(session_id)\n",
    "        \n",
    "        if session_history.messages:\n",
    "            previous_messages = [{\"role\": msg['role'], \"content\": msg['content']} for msg in session_history.messages]\n",
    "            response = chat_with_agent(user_input + \"\\n\\nPrevious Messages: \" + str(previous_messages), agent_executor)\n",
    "        else:\n",
    "            response = chat_with_agent(user_input, agent_executor)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€\n",
    "        session_history.add_message({\"role\": \"user\", \"content\": user_input})\n",
    "        session_history.add_message({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "    print_messages()\n",
    "\n",
    "    # else:\n",
    "    #     st.warning(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.tools import Tool  # ì¶”ê°€ ì„í¬íŠ¸\n",
    "\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ['OPENAI_API_KEY'] = st.secrets[\"OPENAI_API_KEY\"]\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "\n",
    "def load_csv_data(csv_path):\n",
    "    # CSV íŒŒì¼ì—ì„œ ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë¡œë“œ\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´)\n",
    "    df = df.fillna(\"\")\n",
    "    \n",
    "    # ê¸°ì‚¬ ë°ì´í„°ë¥¼ Document í˜•íƒœë¡œ ë³€í™˜\n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=row['Content'],\n",
    "            metadata={\"title\": row['Title'], \"date\": row['date'], \"url\": row['URL']}\n",
    "        )\n",
    "        for _, row in df.iterrows()\n",
    "        if row['Content'].strip()  # Contentê°€ ë¹„ì–´ ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì²˜ë¦¬\n",
    "    ]\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "    retriever = vector.as_retriever()\n",
    "\n",
    "    # ë„êµ¬ë¡œ ë³€í™˜\n",
    "    tool = Tool(\n",
    "        name=\"news_search\",\n",
    "        func=retriever.get_relevant_documents,\n",
    "        description=\"Search for relevant agricultural news articles.\",\n",
    "    )\n",
    "\n",
    "    return tool\n",
    "\n",
    "def load_pdf_files(pdf_paths):\n",
    "    all_documents = []\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        # PyPDFLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë¡œë“œ\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "    split_docs = text_splitter.split_documents(all_documents)\n",
    "\n",
    "    # FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±\n",
    "    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "    retriever = vector.as_retriever()\n",
    "\n",
    "    # ë„êµ¬ ì •ì˜\n",
    "    retriever_tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        name=\"pdf_search\",\n",
    "        description=\"Use this tool to search information from the PDF document.\"\n",
    "    )\n",
    "    return retriever_tool\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜\n",
    "def chat_with_agent(user_input, agent_executor):\n",
    "    result = agent_executor({\"input\": user_input})\n",
    "    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬\n",
    "    return response\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_messages():\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"ë†ì—… ë‰´ìŠ¤ Q&A\", layout=\"wide\", page_icon=\"ğŸŒ¾\")\n",
    "\n",
    "    st.image('Maporter_image.png', width=600)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! 'ëŒ€ë™ ë§ˆí¬í„°' ì…ë‹ˆë‹¤\")  # ì‹œì‘ íƒ€ì´í‹€\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    # íŠ¹ì • PDF ê²½ë¡œ ì§€ì •\n",
    "    # CSV ë°ì´í„° ë¡œë“œ\n",
    "    csv_path = './data/news_classified_updated_utf8.csv'\n",
    "    if csv_path:\n",
    "        pdf_search = load_csv_data(csv_path)\n",
    "        tools = [pdf_search]\n",
    "\n",
    "        # LLM ì„¤ì •\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\",\n",
    "                 \"Be sure to answer in Korean. You are a helpful assistant. \"\n",
    "                 \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n",
    "                 \"Please always include emojis in your responses with a friendly tone. \"\n",
    "                 \"Your name is `ëŒ€ë™ ë§ˆí¬í„°`. Please introduce yourself at the beginning of the conversation.\"\n",
    "                 ''' \n",
    "                 You are a very friendly chatbot called `ëŒ€ë™ ë§ˆí¬í„°`. \\n\\n\n",
    "                 At the beginning of the chatbot conversation, always display the message: \"I am a friendly assistant providing various insights related to agriculture **`based on the latest collected news.`**\"\\n\\n\n",
    "                 \"You are a helpful assistant providing insights based on agricultural news articles collected. \"\n",
    "                 \"Always respond in a professional and friendly tone with structured and informative answers.\"),\n",
    "                Please enter the area you're curious about in relation to agriculture: `ë†ì—…ê³¼ ê´€ë ¨í•œ [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] [ê¸°ìˆ  ë™í–¥] ë¶„ì•¼ ì¤‘ ê¶ê¸ˆí•œ ë¶„ì•¼ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. `\n",
    "                 [ê²½ìŸì‚¬ ì •ë³´]: Our company `ëŒ€ë™`, develops tractors, and our competitors include `LSì— íŠ¸ë¡ `, `TYM`, and `ì¡´ ë””ì–´`.\n",
    "                [ì‹œì¥ ì •ë³´]: For articles containing general information about the agricultural market.\n",
    "                [ê¸°ìˆ  ë™í–¥]: For articles related to the latest or new technologies in the agricultural field, or articles focused on technology.\n",
    "                 \n",
    "                 When summarizing a news article in your response, always use the following #format:\n",
    "                For topics related to [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] [ê¸°ìˆ  ë™í–¥] in agriculture, please find and summarize five relevant news articles using the format above.\n",
    "                #Format\n",
    "\n",
    "                **[ê¸°ì‚¬ ì œëª©]** Title of the news article \\n\\n\n",
    "                **[ê¸°ì‚¬ ë‚ ì§œ]** Date of the news article \\n\\n\n",
    "                **[ë‰´ìŠ¤ ë‚´ìš©]** First, provide a 2â€“3 sentence summary of the overall news content. Then, summarize the main points again in a bullet point format. \\n\\n\n",
    "                **[ë‰´ìŠ¤ ì¶œì²˜]** URL link to the original news article\n",
    "                 \n",
    "                 '''),\n",
    "                (\"placeholder\", \"{chat_history}\"),\n",
    "                (\"human\", \"{input} \\n\\n Be sure to include emoji in your responses.\"),\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„±\n",
    "        agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "        # AgentExecutor ì •ì˜\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "        user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "        if user_input:\n",
    "            response = chat_with_agent(user_input, agent_executor)\n",
    "\n",
    "            # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "            st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "            st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "        print_messages()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
