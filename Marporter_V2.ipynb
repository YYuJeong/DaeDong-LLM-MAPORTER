{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "! pip install -Uq langchain_openai langchain langchain-community streamlit pypdf faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.11.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_experimental in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_experimental) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_experimental) (0.3.19)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.1.143)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.17.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.40.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (18.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, DataFrameLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import tempfile\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import pandas as pd\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "########## 1. í´ë” ë‚´ íŒŒì¼ ë¡œë“œ ##########\n",
    "\n",
    "# í´ë” ê²½ë¡œ ì„¤ì •\n",
    "folder_path = \"./data\"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "\n",
    "# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_pdf_with_metadata(file_path):\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load_and_split(text_splitter)\n",
    "    for doc in documents:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"page\"] = doc.metadata.get(\"page\", \"Unknown\")\n",
    "    return documents\n",
    "\n",
    "# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_excel_with_metadata(file_path):\n",
    "    documents = []\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "        sheet_docs = loader.load_and_split(text_splitter)\n",
    "        for doc in sheet_docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "            doc.metadata[\"sheet_name\"] = sheet_name\n",
    "            doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "        documents.extend(sheet_docs)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_with_metadata(file_path):\n",
    "    documents = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "    csv_docs = loader.load_and_split(text_splitter)\n",
    "    for doc in csv_docs:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "    documents.extend(csv_docs)\n",
    "    return documents\n",
    "\n",
    "# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            documents.extend(load_pdf_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
    "            documents.extend(load_excel_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".csv\"):\n",
    "            documents.extend(load_csv_with_metadata(file_path))\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜\n",
    "def chat_with_agent(user_input, agent_executor):\n",
    "    result = agent_executor({\"input\": user_input})\n",
    "    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬\n",
    "    return response\n",
    "\n",
    "# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in st.session_state.session_history:\n",
    "        st.session_state.session_history[session_ids] = ChatMessageHistory()\n",
    "    return st.session_state.session_history[session_ids]\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_messages():\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ\n",
    "all_docs = load_documents_from_folder(folder_path)\n",
    "\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±\n",
    "vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"csv_search\",\n",
    "    description=\"Use this tool to search information from the csv document\"\n",
    ")\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"AI ë¹„ì„œ\", layout=\"wide\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "    st.image('Marporter.png', width=1200)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ ëŒ€ë™ì´' ì…ë‹ˆë‹¤\")  # ì‹œì‘ íƒ€ì´í‹€\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    if \"session_history\" not in st.session_state:\n",
    "        st.session_state[\"session_history\"] = {}\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.session_state[\"OPENAI_API\"] = st.text_input(label=\"OPENAI API í‚¤\", placeholder=\"Enter Your API Key\", value=\"\", type=\"password\")\n",
    "        st.markdown('---')\n",
    "\n",
    "    # OpenAI API í‚¤ê°€ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    if st.session_state[\"OPENAI_API\"] :\n",
    "        os.environ['OPENAI_API_KEY'] = st.session_state[\"OPENAI_API\"]\n",
    "\n",
    "        # return retriever_tool\n",
    "        tools = [retriever_tool]\n",
    "\n",
    "        # LLM ì„¤ì •\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # Prompt ì •ì˜\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.\n",
    "                    You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.\n",
    "                    Our company is a farming machinery firm called 'ëŒ€ë™'. And Representative domestic competitors are 'TYM' and 'LSì— íŠ¸ë¡ '.\n",
    "                    Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.\n",
    "                    Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                    You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                    When the chat begins, you introduce yourself and ask the user for a keywords in [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥] to search.\n",
    "                    If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].\n",
    "                    Please answer questions following the format [FORMAT] below.\n",
    "                    \n",
    "                    'ê¸°ì‚¬ ì œëª©' is \n",
    "\n",
    "                    #FORMAT\n",
    "                    <ê¸°ì‚¬ ì œëª©>\n",
    "                    ì¼ì :  \n",
    "\n",
    "                    * ìš”ì•½\n",
    "                    -\n",
    "                    -\n",
    "                    -\n",
    "\n",
    "                    ì¶œì²˜ :              \n",
    "                        \"\"\"\n",
    "\n",
    "                ),\n",
    "                (\"placeholder\", \"{chat_history}\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„± (initialize_agent ëŒ€ì‹  create_tool_calling_agent ì‚¬ìš©)\n",
    "        agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "        # AgentExecutor ì •ì˜\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "        user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "        if user_input:\n",
    "            session_id = \"default_session\"\n",
    "            session_history = get_session_history(session_id)\n",
    "\n",
    "            if session_history.messages:\n",
    "                previous_messages = [{\"role\": msg['role'], \"content\": msg['content']} for msg in session_history.messages]\n",
    "                response = chat_with_agent(user_input + \"\\n\\nPrevious Messages: \" + str(previous_messages), agent_executor)\n",
    "            else:\n",
    "                response = chat_with_agent(user_input, agent_executor)\n",
    "\n",
    "            # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "            st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "            st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "            # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€\n",
    "            session_history.add_message({\"role\": \"user\", \"content\": user_input})\n",
    "            session_history.add_message({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "        print_messages()\n",
    "\n",
    "    else:\n",
    "        st.warning(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, DataFrameLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import tempfile\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import pandas as pd\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n",
    "########## 1. í´ë” ë‚´ íŒŒì¼ ë¡œë“œ ##########\n",
    "\n",
    "# í´ë” ê²½ë¡œ ì„¤ì •\n",
    "folder_path = \"./data\"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_pdf_with_metadata(file_path):\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load_and_split(text_splitter)\n",
    "    for doc in documents:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"page\"] = doc.metadata.get(\"page\", \"Unknown\")\n",
    "    return documents\n",
    "\n",
    "# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_excel_with_metadata(file_path):\n",
    "    documents = []\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "        sheet_docs = loader.load_and_split(text_splitter)\n",
    "        for doc in sheet_docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "            doc.metadata[\"sheet_name\"] = sheet_name\n",
    "            doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "        documents.extend(sheet_docs)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_with_metadata(file_path):\n",
    "    documents = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "    csv_docs = loader.load_and_split(text_splitter)\n",
    "    for doc in csv_docs:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "    documents.extend(csv_docs)\n",
    "    return documents\n",
    "\n",
    "# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            documents.extend(load_pdf_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
    "            documents.extend(load_excel_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".csv\"):\n",
    "            documents.extend(load_csv_with_metadata(file_path))\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜\n",
    "def chat_with_agent(user_input, agent_executor):\n",
    "    result = agent_executor({\"input\": user_input})\n",
    "    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬\n",
    "    return response\n",
    "\n",
    "# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in st.session_state.session_history:\n",
    "        st.session_state.session_history[session_ids] = ChatMessageHistory()\n",
    "    return st.session_state.session_history[session_ids]\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_messages():\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ\n",
    "all_docs = load_documents_from_folder(folder_path)\n",
    "\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±\n",
    "vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"csv_search\",\n",
    "    description=\"Use this tool to search information from the csv document\"\n",
    ")\n",
    "\n",
    "# ê²½ìŸì‚¬ ì •ë³´ ë°ì´í„°\n",
    "COMPETITOR_DATA = [\n",
    "    {\n",
    "        \"title\": \"TYM, ì•”ìŠ¤í…Œë¥´ë‹´ì— ìœ ëŸ½ë²•ì¸ ì„¤ë¦½\",\n",
    "        \"date\": \"24-11-18\",\n",
    "        \"summary\": [\n",
    "            \"ì•”ìŠ¤í…Œë¥´ë‹´ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë™ê³¼ ì•„í”„ë¦¬ì¹´ ì‹œì¥ ì§„ì¶œ ê³„íš.\",\n",
    "            \"ìœ ëŸ½ë²•ì¸ì„ í†µí•œ ì‹œì¥ í™•ì¥ ì „ëµ.\",\n",
    "            \"ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œì˜ TYM ê²½ìŸë ¥ ê°•í™” ëª©í‘œ.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.agrinet.co.kr/news/articleView.html?idxno=332410\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"LSíŠ¸ë™í„°, ë¸Œë¼ì§ˆ ë”œëŸ¬ ë„¤íŠ¸ì›Œí¬ í™•ëŒ€\",\n",
    "        \"date\": \"24-11-18\",\n",
    "        \"summary\": [\n",
    "            \"ë¸Œë¼ì§ˆ ë¶ë¶€ ë° ë¶ë™ë¶€ ì§€ì—­ ê³µëµ.\",\n",
    "            \"ë§¤ì¥ í™•ëŒ€ë¥¼ í†µí•´ ì—°ë‚´ ì‹œì¥ ì ìœ ìœ¨ 10% ë‹¬ì„± ëª©í‘œ.\",\n",
    "            \"í˜„ì§€í™” ì „ëµì„ í†µí•´ ê³ ê° ì ‘ê·¼ì„± ê°•í™”.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.theguru.co.kr/news/article.html?no=79892\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"ë§ˆí¬í„°\", layout=\"wide\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "    st.image('chatbot_image.png', width=600)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! ëŒ€ë™ ë§ˆí¬í„° ì…ë‹ˆë‹¤\")  # ì‹œì‘ íƒ€ì´í‹€\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    if \"session_history\" not in st.session_state:\n",
    "        st.session_state[\"session_history\"] = {}\n",
    "\n",
    "    # with st.sidebar:\n",
    "    #     st.session_state[\"OPENAI_API\"] = st.text_input(label=\"OPENAI API í‚¤\", placeholder=\"Enter Your API Key\", value=\"\", type=\"password\")\n",
    "    #     st.markdown('---')\n",
    "\n",
    "    # # OpenAI API í‚¤ê°€ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    # if st.session_state[\"OPENAI_API\"] :\n",
    "    #     os.environ['OPENAI_API_KEY'] = st.session_state[\"OPENAI_API\"]\n",
    "\n",
    "# return retriever_tool\n",
    "    tools = [retriever_tool]\n",
    "\n",
    "    # LLM ì„¤ì •\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # Prompt ì •ì˜\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"\n",
    "                You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.\n",
    "                Your name is `ë§ˆí¬í„°`.\n",
    "                You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.\n",
    "                Our company is a farming machinery firm called 'ëŒ€ë™'. and Representative domestic competitors include 'TYM' and 'LSì— íŠ¸ë¡ '.\n",
    "                Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.\n",
    "                Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                When the chatbot begins, you should introduce yourself and ask the user for a keywords to search.\n",
    "                If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].\n",
    "                Please answer questions following the format [FORMAT] below.\n",
    "                `ìš”ì•½` should include a condensed version of the article's content. \n",
    "                Include the title in the `ê¸°ì‚¬ ì œëª©` section.   \n",
    "                    \n",
    "\n",
    "                #FORMAT\n",
    "                [ê¸°ì‚¬ ì œëª©] \n",
    "                ì¼ì :  \n",
    "\n",
    "                * ìš”ì•½\n",
    "                -\n",
    "                -\n",
    "                -\n",
    "\n",
    "                ì¶œì²˜ :              \n",
    "                    \n",
    "                    \"\"\"\n",
    "\n",
    "            ),\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ì—ì´ì „íŠ¸ ìƒì„± (initialize_agent ëŒ€ì‹  create_tool_calling_agent ì‚¬ìš©)\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "    # AgentExecutor ì •ì˜\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "    if user_input:\n",
    "        session_id = \"default_session\"\n",
    "        session_history = get_session_history(session_id)\n",
    "        \n",
    "        if session_history.messages:\n",
    "            previous_messages = [{\"role\": msg['role'], \"content\": msg['content']} for msg in session_history.messages]\n",
    "            response = chat_with_agent(user_input + \"\\n\\nPrevious Messages: \" + str(previous_messages), agent_executor)\n",
    "        else:\n",
    "            response = chat_with_agent(user_input, agent_executor)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€\n",
    "        session_history.add_message({\"role\": \"user\", \"content\": user_input})\n",
    "        session_history.add_message({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "    print_messages()\n",
    "\n",
    "    # else:\n",
    "    #     st.warning(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot1.py \n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "load_dotenv()\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_from_folder(folder_path):\n",
    "    \"\"\"data í´ë” ì•ˆì˜ ëª¨ë“  CSV íŒŒì¼ì„ ì½ì–´ì„œ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•©ì¹¨\"\"\"\n",
    "    all_dataframes = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_dataframes.append(df)\n",
    "    if all_dataframes:\n",
    "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No CSV files found in the specified folder.\")\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë¡œë“œ\n",
    "folder_path = \"./data\"\n",
    "df = load_csv_from_folder(folder_path)\n",
    "\n",
    "custom_prefix = \"\"\"\n",
    "                You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.\n",
    "                Your name is `ë§ˆí¬í„°`.\n",
    "                You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.\n",
    "                Our company is a farming machinery firm called 'ëŒ€ë™'. and Representative domestic competitors include 'TYM' and 'LSì— íŠ¸ë¡ '.\n",
    "                Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.\n",
    "                Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                When the chatbot begins, you should introduce yourself and ask the user for a keywords to search.\n",
    "                If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].\n",
    "                Please answer questions following the format [FORMAT] below.\n",
    "                `ìš”ì•½` should include a condensed version of the article's content. \n",
    "                Include the title in the `ê¸°ì‚¬ ì œëª©` section.   \n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "custom_suffix = \"\"\"\n",
    "                #FORMAT\n",
    "                [ê¸°ì‚¬ ì œëª©] \n",
    "                ì¼ì :  \n",
    "\n",
    "                * ìš”ì•½\n",
    "                -\n",
    "                -\n",
    "                -\n",
    "\n",
    "                ì¶œì²˜ :  \n",
    "                \"\"\"\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"ë§ˆí¬í„°\", layout=\"wide\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "    st.image('chatbot_image.png', width=600)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! ëŒ€ë™ ë§ˆí¬í„° ì…ë‹ˆë‹¤\")\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    # LLM ì„¤ì •\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "    # ì—ì´ì „íŠ¸ ìƒì„±\n",
    "    agent = create_pandas_dataframe_agent(llm, df , \n",
    "                prefix = custom_prefix, \n",
    "                suffix = custom_suffix,\n",
    "                allow_dangerous_code=True, verbose=True)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "    if user_input:\n",
    "        # ì—ì´ì „íŠ¸ë¥¼ í†µí•´ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "        response = agent.run(user_input)\n",
    "\n",
    "        # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, DataFrameLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import tempfile\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import pandas as pd\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ['OPENAI_API_KEY'] = st.secrets[\"OPENAI_API_KEY\"]\n",
    "# í´ë” ê²½ë¡œ ì„¤ì •\n",
    "folder_path = \"./data\"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_pdf_with_metadata(file_path):\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load_and_split(text_splitter)\n",
    "    for doc in documents:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"page\"] = doc.metadata.get(\"page\", \"Unknown\")\n",
    "    return documents\n",
    "\n",
    "# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_excel_with_metadata(file_path):\n",
    "    documents = []\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "        sheet_docs = loader.load_and_split(text_splitter)\n",
    "        for doc in sheet_docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "            doc.metadata[\"sheet_name\"] = sheet_name\n",
    "            doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "        documents.extend(sheet_docs)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_csv_with_metadata(file_path):\n",
    "    documents = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    loader = DataFrameLoader(df, page_content_column=df.columns[0])\n",
    "    csv_docs = loader.load_and_split(text_splitter)\n",
    "    for doc in csv_docs:\n",
    "        doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "        doc.metadata[\"cell_range\"] = f\"A1:{df.columns[-1]}{len(df)}\"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´\n",
    "    documents.extend(csv_docs)\n",
    "    return documents\n",
    "\n",
    "# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            documents.extend(load_pdf_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
    "            documents.extend(load_excel_with_metadata(file_path))\n",
    "        elif file_name.endswith(\".csv\"):\n",
    "            documents.extend(load_csv_with_metadata(file_path))\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜\n",
    "def chat_with_agent(user_input, agent_executor):\n",
    "    result = agent_executor({\"input\": user_input})\n",
    "    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬\n",
    "    return response\n",
    "\n",
    "# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in st.session_state.session_history:\n",
    "        st.session_state.session_history[session_ids] = ChatMessageHistory()\n",
    "    return st.session_state.session_history[session_ids]\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_messages():\n",
    "    for msg in st.session_state[\"messages\"]:\n",
    "        st.chat_message(msg['role']).write(msg['content'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ\n",
    "all_docs = load_documents_from_folder(folder_path)\n",
    "\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±\n",
    "vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"csv_search\",\n",
    "    description=\"Use this tool to search information from the csv document\"\n",
    ")\n",
    "# ê²½ìŸì‚¬ ì •ë³´\n",
    "COMPETITOR_DATA = [\n",
    "    {\n",
    "        \"title\": \"ë†ìì¬ì—…ì²´ â€˜ìƒì£¼ìŒ€â€™ ì†Œë¹„ì´‰ì§„ ìº í˜ì¸ ë™ì°¸\",\n",
    "        \"date\": \"24-11-11\",\n",
    "        \"summary\": [\n",
    "            \"êµ­ë‚´ ë†ìì¬ì—…ì²´ë“¤ì´ ìŒ€ ì†Œë¹„ì´‰ì§„ ìº í˜ì¸ì— ë™ì°¸.\",\n",
    "            \"TYM, ë™ë°©ì•„ê·¸ë¡œ, ëŒ€ë™ê³µì—…ì´ ìº í˜ì¸ í˜‘ì•½ì‹ ì°¸ì—¬.\",\n",
    "            \"ì§ì› ì‹ë‹¹ì—ì„œ ê¸‰ì‹ìš© ìŒ€ë¡œ ìº í˜ì¸ í™•ì‚° ê¸°ì—¬.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500311\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"TYM, ì„¸ê³„ 4ëŒ€ ë†ê¸°ê³„ ì „ì‹œíšŒ â€˜EIMAâ€™ ì°¸ê°€\",\n",
    "        \"date\": \"24-11-08\",\n",
    "        \"summary\": [\n",
    "            \"ì´íƒˆë¦¬ì•„ ë³¼ë¡œëƒì—ì„œ ì—´ë¦° êµ­ì œ ë†ì—…ê¸°ê³„ ë°•ëŒíšŒ â€˜EIMA 2024â€™ ì°¸ê°€.\",\n",
    "            \"ì‹ ì œí’ˆ íŠ¸ë™í„° â€˜T115â€™ ë° â€˜T130â€™ ì „ì‹œ.\",\n",
    "            \"êµ­ë‚´ ë†ê¸°ê³„ ì—…ì²´ ì¤‘ ìœ ì¼í•˜ê²Œ ì°¸ê°€í•˜ì—¬ ê¸€ë¡œë²Œ ê¸°ìˆ ë ¥ í™ë³´.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500274\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"â€œí•œêµ­ ë†ê¸°ê³„ ì´ë ‡ìŠµë‹ˆë‹¤â€â€¦TYM, ë¶ë¯¸ ìš°ìˆ˜ ë”œëŸ¬ êµ­ë‚´ ì´ˆì²­ í–‰ì‚¬ ì—´ì–´\",\n",
    "        \"date\": \"24-11-06\",\n",
    "        \"summary\": [\n",
    "            \"ë¶ë¯¸ ìš°ìˆ˜ ë”œëŸ¬ë¥¼ êµ­ë‚´ë¡œ ì´ˆì²­í•˜ì—¬ ë†ê¸°ê³„ ì‹œìŠ¹ ë° í’ˆí‰íšŒ ì§„í–‰.\",\n",
    "            \"ìµì‚°, ì˜¥ì²œ ê³µì¥ì—ì„œ ê¸€ë¡œë²Œ ë¹„ì „ ë° ì„±ì¥ ì „ëµ ê³µìœ .\",\n",
    "            \"ì‹ ì œí’ˆ ì²´í—˜ìœ¼ë¡œ ê¸€ë¡œë²Œ ë”œëŸ¬ì™€ ìƒìƒ í˜‘ë ¥ ê°•í™”.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500251\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì‹œì¥ ì •ë³´\n",
    "MARKET_DATA = [\n",
    "    {\n",
    "        \"title\": \"ë¶€ì •ì—¬ë¡  í™•ì‚°â€¦ê°€ë½ì‹œì¥ 12ì›” íœ´ì¥ ì² íšŒ\",\n",
    "        \"date\": \"24-11-18\",\n",
    "        \"summary\": [\n",
    "            \"ì„œìš¸ì‹œë†ìˆ˜ì‚°ì‹í’ˆê³µì‚¬ê°€ ê°€ë½ì‹œì¥ ì£¼ 5ì¼ì œ ë™ì ˆê¸° ì‹œë²”íœ´ì—… ê³„íš ì¼ë¶€ ì² íšŒ.\",\n",
    "            \"ì œì£¼ ë“± ê²¨ìš¸ì±„ì†Œ ì£¼ì‚°ì§€ ë†ë¯¼ë“¤ì˜ í”¼í•´ë¥¼ ìš°ë ¤í•˜ì—¬ ê²°ì •.\",\n",
    "            \"ì¶œí•˜ ë†ë¯¼ê³¼ ì‹œì¥ ìœ í†µ êµ¬ì¡°ì— ëŒ€í•œ ê°œì„  ìš”êµ¬ ì§€ì†.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500226\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"[ë§›ìˆëŠ” ì´ì•¼ê¸°] íˆ¬ë°•í•¨ ì† ì˜ì–‘ ê°€ë“â€¦ì–´ë¨¸ë‹ˆ ë– ì˜¤ë¥´ëŠ” í‘¸ê·¼í•œ ë§› â€˜í˜¸ë°•â€™\",\n",
    "        \"date\": \"24-11-18\",\n",
    "        \"summary\": [\n",
    "            \"í˜¸ë°•ì´ ë‹¤ì–‘í•œ ìš”ë¦¬ì— í™œìš©ë˜ë©° í™˜ì ˆê¸° ë³´ì–‘ ìŒì‹ìœ¼ë¡œ ì£¼ëª©ë°›ìŒ.\",\n",
    "            \"ì¼ë¶€ ì§€ì—­ì—ì„œëŠ” ê¹€ì¹˜ë‚˜ ì°Œê°œ ì¬ë£Œë¡œ í™œìš©ë˜ë©° ì˜ì–‘ ë©´ì—ì„œë„ ìš°ìˆ˜.\",\n",
    "            \"ë‹¤ì´ì–´íŠ¸ ë° ì†Œí™”ì— ë„ì›€ì„ ì£¼ëŠ” ê±´ê°•ì‹í’ˆìœ¼ë¡œ í‰ê°€.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500494\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"[íŒë§¤ë†í˜‘ì´ ê°„ë‹¤] ê³ í’ˆì§ˆ í¬ë„ â€˜ìœ í†µ ì¼ë²ˆì§€â€™â€¦ë§›ê³¼ ì‹ ë¢°ê°€ ë¹„ê²°\",\n",
    "        \"date\": \"24-11-18\",\n",
    "        \"summary\": [\n",
    "            \"ê²½ë¶ ì„œìƒì£¼ë†í˜‘ì´ ê³ í’ˆì§ˆ ìƒ¤ì¸ë¨¸ìŠ¤ìº£ê³¼ ìº ë²¨ì–¼ë¦¬ í¬ë„ ìœ í†µì„ ì£¼ë„.\",\n",
    "            \"ì—°ê°„ 1ë§Œ í†¤ ì´ìƒì˜ ì·¨ê¸‰ëŸ‰ìœ¼ë¡œ ì•½ 710ì–µ ì›ì˜ ë§¤ì¶œ ê¸°ë¡.\",\n",
    "            \"ì˜ë† êµìœ¡ ë° ë†ì—…ì¸ê³¼ì˜ í˜‘ë ¥ì„ í†µí•´ í’ˆì§ˆ ìœ ì§€ ë° ì˜¨ë¼ì¸ ê±°ë˜ í™•ì¥.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500603\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ê¸°ìˆ  ë™í–¥\n",
    "TECH_DATA = [\n",
    "    {\n",
    "        \"title\": \"ë†í˜‘ì€í–‰, ë¹…ë°ì´í„°Â·AI ê¸°ë°˜ ê¸°ì—…ëŒ€ì¶œ ì‹¬ì‚¬ì‹œìŠ¤í…œ ë„ì…\",\n",
    "        \"date\": \"2024-11-18\",\n",
    "        \"summary\": [\n",
    "            \"ë¹…ë°ì´í„°ì™€ AIë¥¼ í™œìš©í•´ ì‹ ìš©í‰ê°€ ì •í™•ë„ ë° ì‹¬ì‚¬ íš¨ìœ¨ì„± ì œê³ .\",\n",
    "            \"ê¸ˆìœµ ì ‘ê·¼ì„±ì„ í™•ëŒ€í•˜ê³  ì¤‘ì†Œê¸°ì—… ëŒ€ì¶œ í™œì„±í™” ê¸°ëŒ€.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500374\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ì •í¬ìš© ì˜ì›, ì¸ê³µì§€ëŠ¥ì‚°ì—… ì²´ê³„ì  ìœ¡ì„± ìœ„í•œ ë²•ì•ˆ ë°œì˜\",\n",
    "        \"date\": \"2024-11-18\",\n",
    "        \"summary\": [\n",
    "            \"AI ì—°êµ¬ê°œë°œ(R&D) íˆ¬ìì™€ ê·œì œ ì™„í™”ë¥¼ í†µí•œ í˜ì‹  ì´‰ì§„.\",\n",
    "            \"AI ì¸ì¬ ìœ¡ì„± ë°©ì•ˆì„ í¬í•¨í•˜ì—¬ ê²½ì œì  íŒŒê¸‰ë ¥ ì¦ëŒ€ ì „ë§.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500336\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ë†í˜‘ì‚¬ë£Œ ê²½ë‚¨ì§€ì‚¬, ê°€ì¶•ì „ì—¼ë³‘ ì°¨ë‹¨ ìœ„í•œ ë†ê°€ ë°©ì—­ì§€ì› ê°•í™” ë‚˜ì„œ\",\n",
    "        \"date\": \"2024-11-18\",\n",
    "        \"summary\": [\n",
    "            \"ê°€ì¶•ì „ì—¼ë³‘ í™•ì‚° ë°©ì§€ë¥¼ ìœ„í•´ ë°©ì—­ ì§€ì› í™œë™ ê°•í™”.\",\n",
    "            \"AI ê¸°ìˆ ì„ í™œìš©í•œ ë°©ì—­ ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ì˜ˆì¸¡ë ¥ í–¥ìƒ ë„ëª¨.\"\n",
    "        ],\n",
    "        \"source\": \"https://www.nongmin.com/article/20241118500381\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Streamlit ë©”ì¸ ì½”ë“œ\n",
    "def main():\n",
    "    # í˜ì´ì§€ ì„¤ì •\n",
    "    st.set_page_config(page_title=\"ë§ˆí¬í„°\", layout=\"wide\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "    st.image('chatbot_image.PNG', width=600)\n",
    "    st.markdown('---')\n",
    "    st.title(\"ì•ˆë…•í•˜ì„¸ìš”! ëŒ€ë™ ë§ˆí¬í„° ì…ë‹ˆë‹¤\")  # ì‹œì‘ íƒ€ì´í‹€\n",
    "\n",
    "    # ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    if \"session_history\" not in st.session_state:\n",
    "        st.session_state[\"session_history\"] = {}\n",
    "\n",
    "    tools = [retriever_tool]\n",
    "\n",
    "    # LLM ì„¤ì •\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # Prompt ì •ì˜\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"\n",
    "                You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.\n",
    "                Your name is `ë§ˆí¬í„°`.\n",
    "                You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.\n",
    "                Our company is a farming machinery firm called 'ëŒ€ë™'. and Representative domestic competitors include 'TYM' and 'LSì— íŠ¸ë¡ '.\n",
    "                Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.\n",
    "                Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].\n",
    "                When the chatbot begins, you should introduce yourself and ask the user for a keywords to search.\n",
    "                If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].\n",
    "                Please answer questions following the format [FORMAT] below.\n",
    "                `ìš”ì•½` should include a condensed version of the article's content. \n",
    "                Include the title in the `ê¸°ì‚¬ ì œëª©` section.   \n",
    "\n",
    "                #FORMAT\n",
    "                [ê¸°ì‚¬ ì œëª©] \n",
    "                * ì¼ì :  \n",
    "\n",
    "                * ìš”ì•½\n",
    "                -\n",
    "                -\n",
    "                -\n",
    "\n",
    "                ì¶œì²˜ :              \n",
    "                    \n",
    "                \"\"\"\n",
    "            ),\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ì—ì´ì „íŠ¸ ìƒì„±\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "    # AgentExecutor ì •ì˜\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')\n",
    "\n",
    "    if user_input:\n",
    "        session_id = \"default_session\"\n",
    "        session_history = get_session_history(session_id)\n",
    "\n",
    "        # ì¡°ê±´ë¬¸ ìˆ˜ì •\n",
    "        if \"ê²½ìŸì‚¬ ì •ë³´\" in user_input:\n",
    "            # ê²½ìŸì‚¬ ì •ë³´ ë°˜í™˜\n",
    "            data_source = COMPETITOR_DATA\n",
    "        elif \"ì‹œì¥ ì •ë³´\" in user_input:\n",
    "            # ì‹œì¥ ì •ë³´ ë°˜í™˜\n",
    "            data_source = MARKET_DATA\n",
    "        elif \"ê¸°ìˆ  ë™í–¥\" in user_input:\n",
    "            # ê¸°ìˆ  ë™í–¥ ë°˜í™˜\n",
    "            data_source = TECH_DATA\n",
    "        else:\n",
    "            data_source = None\n",
    "\n",
    "        if data_source is not None:\n",
    "            response = \"\\n\".join(\n",
    "                [\n",
    "                    f\"[ê¸°ì‚¬ ì œëª©] {item['title']}\\nì¼ì: {item['date']}\\n* ìš”ì•½\\n\" + \"\\n\".join(f\"- {summary}\" for summary in item['summary']) + f\"\\nì¶œì²˜: {item['source']}\\n\"\n",
    "                    for item in data_source\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            # ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "            if session_history.messages:\n",
    "                previous_messages = [{\"role\": msg['role'], \"content\": msg['content']} for msg in session_history.messages]\n",
    "                response = chat_with_agent(user_input + \"\\n\\nPrevious Messages: \" + str(previous_messages), agent_executor)\n",
    "            else:\n",
    "                response = chat_with_agent(user_input, agent_executor)\n",
    "\n",
    "        # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€\n",
    "        session_history.add_message({\"role\": \"user\", \"content\": user_input})\n",
    "        session_history.add_message({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "\n",
    "    # ëŒ€í™” ë‚´ìš© ì¶œë ¥\n",
    "    print_messages()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
