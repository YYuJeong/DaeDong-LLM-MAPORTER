
import os
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader, DataFrameLoader
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.tools.retriever import create_retriever_tool
from langchain.prompts import ChatPromptTemplate
import tempfile
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import create_tool_calling_agent, AgentExecutor
import pandas as pd
# .env íŒŒì¼ ë¡œë“œ
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
os.environ['OPENAI_API_KEY'] = st.secrets["OPENAI_API_KEY"]

# í´ë” ê²½ë¡œ ì„¤ì •
folder_path = "./data"  # ë¶„ì„í•  íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ
text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)

# PDF ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_pdf_with_metadata(file_path):
    loader = PyMuPDFLoader(file_path)
    documents = loader.load_and_split(text_splitter)
    for doc in documents:
        doc.metadata["source"] = os.path.basename(file_path)
        doc.metadata["page"] = doc.metadata.get("page", "Unknown")
    return documents

# ì—‘ì…€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_excel_with_metadata(file_path):
    documents = []
    xls = pd.ExcelFile(file_path)
    for sheet_name in xls.sheet_names:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        loader = DataFrameLoader(df, page_content_column=df.columns[0])
        sheet_docs = loader.load_and_split(text_splitter)
        for doc in sheet_docs:
            doc.metadata["source"] = os.path.basename(file_path)
            doc.metadata["sheet_name"] = sheet_name
            doc.metadata["cell_range"] = f"A1:{df.columns[-1]}{len(df)}"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´
        documents.extend(sheet_docs)
    return documents


# CSV ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_csv_with_metadata(file_path):
    documents = []
    df = pd.read_csv(file_path)
    loader = DataFrameLoader(df, page_content_column=df.columns[0])
    csv_docs = loader.load_and_split(text_splitter)
    for doc in csv_docs:
        doc.metadata["source"] = os.path.basename(file_path)
        doc.metadata["cell_range"] = f"A1:{df.columns[-1]}{len(df)}"  # ì¶”ê°€ ì…€ ë²”ìœ„ ì •ë³´
    documents.extend(csv_docs)
    return documents

# í´ë” ë‚´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œ

def load_documents_from_folder(folder_path):
    documents = []
    for file_name in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file_name)
        if file_name.endswith(".pdf"):
            documents.extend(load_pdf_with_metadata(file_path))
        elif file_name.endswith(".xlsx") or file_name.endswith(".xls"):
            documents.extend(load_excel_with_metadata(file_path))
        elif file_name.endswith(".csv"):
            documents.extend(load_csv_with_metadata(file_path))
    return documents



# ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜
def chat_with_agent(user_input, agent_executor):
    result = agent_executor({"input": user_input})
    response = result['output']  # ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ í‚¤ë¥¼ ì²˜ë¦¬
    return response

# ì„¸ì…˜ ê¸°ë¡ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids):
    if session_ids not in st.session_state.session_history:
        st.session_state.session_history[session_ids] = ChatMessageHistory()
    return st.session_state.session_history[session_ids]

# ëŒ€í™” ë‚´ìš© ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def print_messages():
    for msg in st.session_state["messages"]:
        st.chat_message(msg['role']).write(msg['content'])


# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
all_docs = load_documents_from_folder(folder_path)


# FAISS ì¸ë±ìŠ¤ ì„¤ì • ë° ìƒì„±
vector = FAISS.from_documents(all_docs, OpenAIEmbeddings())
retriever = vector.as_retriever()

# ë„êµ¬ ì •ì˜
retriever_tool = create_retriever_tool(
    retriever,
    name="csv_search",
    description="Use this tool to search information from the csv document"
)
# ê²½ìŸì‚¬ ì •ë³´
COMPETITOR_DATA = [
    {
        "title": "ë†ìì¬ì—…ì²´ â€˜ìƒì£¼ìŒ€â€™ ì†Œë¹„ì´‰ì§„ ìº í˜ì¸ ë™ì°¸",
        "date": "24-11-11",
        "summary": [
            "êµ­ë‚´ ë†ìì¬ì—…ì²´ë“¤ì´ ìŒ€ ì†Œë¹„ì´‰ì§„ ìº í˜ì¸ì— ë™ì°¸.",
            "TYM, ë™ë°©ì•„ê·¸ë¡œ, ëŒ€ë™ê³µì—…ì´ ìº í˜ì¸ í˜‘ì•½ì‹ ì°¸ì—¬.",
            "ì§ì› ì‹ë‹¹ì—ì„œ ê¸‰ì‹ìš© ìŒ€ë¡œ ìº í˜ì¸ í™•ì‚° ê¸°ì—¬."
        ],
        "source": "https://www.nongmin.com/article/20241118500311"
    },
    {
        "title": "TYM, ì„¸ê³„ 4ëŒ€ ë†ê¸°ê³„ ì „ì‹œíšŒ â€˜EIMAâ€™ ì°¸ê°€",
        "date": "24-11-08",
        "summary": [
            "ì´íƒˆë¦¬ì•„ ë³¼ë¡œëƒì—ì„œ ì—´ë¦° êµ­ì œ ë†ì—…ê¸°ê³„ ë°•ëŒíšŒ â€˜EIMA 2024â€™ ì°¸ê°€.",
            "ì‹ ì œí’ˆ íŠ¸ë™í„° â€˜T115â€™ ë° â€˜T130â€™ ì „ì‹œ.",
            "êµ­ë‚´ ë†ê¸°ê³„ ì—…ì²´ ì¤‘ ìœ ì¼í•˜ê²Œ ì°¸ê°€í•˜ì—¬ ê¸€ë¡œë²Œ ê¸°ìˆ ë ¥ í™ë³´."
        ],
        "source": "https://www.nongmin.com/article/20241118500274"
    },
    {
        "title": "â€œí•œêµ­ ë†ê¸°ê³„ ì´ë ‡ìŠµë‹ˆë‹¤â€â€¦TYM, ë¶ë¯¸ ìš°ìˆ˜ ë”œëŸ¬ êµ­ë‚´ ì´ˆì²­ í–‰ì‚¬ ì—´ì–´",
        "date": "24-11-06",
        "summary": [
            "ë¶ë¯¸ ìš°ìˆ˜ ë”œëŸ¬ë¥¼ êµ­ë‚´ë¡œ ì´ˆì²­í•˜ì—¬ ë†ê¸°ê³„ ì‹œìŠ¹ ë° í’ˆí‰íšŒ ì§„í–‰.",
            "ìµì‚°, ì˜¥ì²œ ê³µì¥ì—ì„œ ê¸€ë¡œë²Œ ë¹„ì „ ë° ì„±ì¥ ì „ëµ ê³µìœ .",
            "ì‹ ì œí’ˆ ì²´í—˜ìœ¼ë¡œ ê¸€ë¡œë²Œ ë”œëŸ¬ì™€ ìƒìƒ í˜‘ë ¥ ê°•í™”."
        ],
        "source": "https://www.nongmin.com/article/20241118500251"
    }
]

# ì‹œì¥ ì •ë³´
MARKET_DATA = [
    {
        "title": "ë¶€ì •ì—¬ë¡  í™•ì‚°â€¦ê°€ë½ì‹œì¥ 12ì›” íœ´ì¥ ì² íšŒ",
        "date": "24-11-18",
        "summary": [
            "ì„œìš¸ì‹œë†ìˆ˜ì‚°ì‹í’ˆê³µì‚¬ê°€ ê°€ë½ì‹œì¥ ì£¼ 5ì¼ì œ ë™ì ˆê¸° ì‹œë²”íœ´ì—… ê³„íš ì¼ë¶€ ì² íšŒ.",
            "ì œì£¼ ë“± ê²¨ìš¸ì±„ì†Œ ì£¼ì‚°ì§€ ë†ë¯¼ë“¤ì˜ í”¼í•´ë¥¼ ìš°ë ¤í•˜ì—¬ ê²°ì •.",
            "ì¶œí•˜ ë†ë¯¼ê³¼ ì‹œì¥ ìœ í†µ êµ¬ì¡°ì— ëŒ€í•œ ê°œì„  ìš”êµ¬ ì§€ì†."
        ],
        "source": "https://www.nongmin.com/article/20241118500226"
    },
    {
        "title": "[ë§›ìˆëŠ” ì´ì•¼ê¸°] íˆ¬ë°•í•¨ ì† ì˜ì–‘ ê°€ë“â€¦ì–´ë¨¸ë‹ˆ ë– ì˜¤ë¥´ëŠ” í‘¸ê·¼í•œ ë§› â€˜í˜¸ë°•â€™",
        "date": "24-11-18",
        "summary": [
            "í˜¸ë°•ì´ ë‹¤ì–‘í•œ ìš”ë¦¬ì— í™œìš©ë˜ë©° í™˜ì ˆê¸° ë³´ì–‘ ìŒì‹ìœ¼ë¡œ ì£¼ëª©ë°›ìŒ.",
            "ì¼ë¶€ ì§€ì—­ì—ì„œëŠ” ê¹€ì¹˜ë‚˜ ì°Œê°œ ì¬ë£Œë¡œ í™œìš©ë˜ë©° ì˜ì–‘ ë©´ì—ì„œë„ ìš°ìˆ˜.",
            "ë‹¤ì´ì–´íŠ¸ ë° ì†Œí™”ì— ë„ì›€ì„ ì£¼ëŠ” ê±´ê°•ì‹í’ˆìœ¼ë¡œ í‰ê°€."
        ],
        "source": "https://www.nongmin.com/article/20241118500494"
    },
    {
        "title": "[íŒë§¤ë†í˜‘ì´ ê°„ë‹¤] ê³ í’ˆì§ˆ í¬ë„ â€˜ìœ í†µ ì¼ë²ˆì§€â€™â€¦ë§›ê³¼ ì‹ ë¢°ê°€ ë¹„ê²°",
        "date": "24-11-18",
        "summary": [
            "ê²½ë¶ ì„œìƒì£¼ë†í˜‘ì´ ê³ í’ˆì§ˆ ìƒ¤ì¸ë¨¸ìŠ¤ìº£ê³¼ ìº ë²¨ì–¼ë¦¬ í¬ë„ ìœ í†µì„ ì£¼ë„.",
            "ì—°ê°„ 1ë§Œ í†¤ ì´ìƒì˜ ì·¨ê¸‰ëŸ‰ìœ¼ë¡œ ì•½ 710ì–µ ì›ì˜ ë§¤ì¶œ ê¸°ë¡.",
            "ì˜ë† êµìœ¡ ë° ë†ì—…ì¸ê³¼ì˜ í˜‘ë ¥ì„ í†µí•´ í’ˆì§ˆ ìœ ì§€ ë° ì˜¨ë¼ì¸ ê±°ë˜ í™•ì¥."
        ],
        "source": "https://www.nongmin.com/article/20241118500603"
    }
]

# ê¸°ìˆ  ë™í–¥
TECH_DATA = [
    {
        "title": "ë†í˜‘ì€í–‰, ë¹…ë°ì´í„°Â·AI ê¸°ë°˜ ê¸°ì—…ëŒ€ì¶œ ì‹¬ì‚¬ì‹œìŠ¤í…œ ë„ì…",
        "date": "2024-11-18",
        "summary": [
            "ë¹…ë°ì´í„°ì™€ AIë¥¼ í™œìš©í•´ ì‹ ìš©í‰ê°€ ì •í™•ë„ ë° ì‹¬ì‚¬ íš¨ìœ¨ì„± ì œê³ .",
            "ê¸ˆìœµ ì ‘ê·¼ì„±ì„ í™•ëŒ€í•˜ê³  ì¤‘ì†Œê¸°ì—… ëŒ€ì¶œ í™œì„±í™” ê¸°ëŒ€."
        ],
        "source": "https://www.nongmin.com/article/20241118500374"
    },
    {
        "title": "ì •í¬ìš© ì˜ì›, ì¸ê³µì§€ëŠ¥ì‚°ì—… ì²´ê³„ì  ìœ¡ì„± ìœ„í•œ ë²•ì•ˆ ë°œì˜",
        "date": "2024-11-18",
        "summary": [
            "AI ì—°êµ¬ê°œë°œ(R&D) íˆ¬ìì™€ ê·œì œ ì™„í™”ë¥¼ í†µí•œ í˜ì‹  ì´‰ì§„.",
            "AI ì¸ì¬ ìœ¡ì„± ë°©ì•ˆì„ í¬í•¨í•˜ì—¬ ê²½ì œì  íŒŒê¸‰ë ¥ ì¦ëŒ€ ì „ë§."
        ],
        "source": "https://www.nongmin.com/article/20241118500336"
    },
    {
        "title": "ë†í˜‘ì‚¬ë£Œ ê²½ë‚¨ì§€ì‚¬, ê°€ì¶•ì „ì—¼ë³‘ ì°¨ë‹¨ ìœ„í•œ ë†ê°€ ë°©ì—­ì§€ì› ê°•í™” ë‚˜ì„œ",
        "date": "2024-11-18",
        "summary": [
            "ê°€ì¶•ì „ì—¼ë³‘ í™•ì‚° ë°©ì§€ë¥¼ ìœ„í•´ ë°©ì—­ ì§€ì› í™œë™ ê°•í™”.",
            "AI ê¸°ìˆ ì„ í™œìš©í•œ ë°©ì—­ ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ì˜ˆì¸¡ë ¥ í–¥ìƒ ë„ëª¨."
        ],
        "source": "https://www.nongmin.com/article/20241118500381"
    }
]

# Streamlit ë©”ì¸ ì½”ë“œ
def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(page_title="ë§ˆí¬í„°", layout="wide", page_icon="ğŸ¤–")

    st.image('chatbot_image.png', width=600)
    st.markdown('---')
    st.title("ì•ˆë…•í•˜ì„¸ìš”! ëŒ€ë™ ë§ˆí¬í„° ì…ë‹ˆë‹¤")  # ì‹œì‘ íƒ€ì´í‹€

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}

    tools = [retriever_tool]

    # LLM ì„¤ì •
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

    # Prompt ì •ì˜
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
                You Should answer the user's questions in a friendly and kind manner. And should answer in Korean.
                Your name is `ë§ˆí¬í„°`.
                You are a 15-year veteran market information analyst specializing in agriculture, agricultural machinery, future agriculture, and smart mobility in our company.
                Our company is a farming machinery firm called 'ëŒ€ë™'. and Representative domestic competitors include 'TYM' and 'LSì— íŠ¸ë¡ '.
                Our company revenue structure is based on two main channels: domestic sales in South Korea and exports to regions such as Southeast Asia, the United States, and Europe. The revenue comes from parts, products, and services.
                Analyze the 'Title', 'Subheading', 'Content', and 'date' columns of the dataframe (df) to classify each article into one of the following categories: [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].
                You have news articles from the last two weeks related to keywords such as [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] and [ê¸°ìˆ  ë™í–¥].
                When the chatbot begins, you should introduce yourself and ask the user for a keywords to search.
                If the keyword provided by the user does not match the pre-defined keyword format, you determine the user's intent and confirm if it matches a request related to the keywords [ì •ì¹˜/ì‚¬íšŒ], [ê²½ìŸì‚¬ ì •ë³´], [ì‹œì¥ ì •ë³´] or [ê¸°ìˆ  ë™í–¥].
                Please answer questions following the format [FORMAT] below.
                `ìš”ì•½` should include a condensed version of the article's content. 
                Include the title in the `ê¸°ì‚¬ ì œëª©` section.   

                #FORMAT
                [ê¸°ì‚¬ ì œëª©] 
                * ì¼ì :  

                * ìš”ì•½
                -
                -
                -

                ì¶œì²˜ :              
                    
                """
            ),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ]
    )

    # ì—ì´ì „íŠ¸ ìƒì„±
    agent = create_tool_calling_agent(llm, tools, prompt)

    # AgentExecutor ì •ì˜
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')

    if user_input:
        session_id = "default_session"
        session_history = get_session_history(session_id)

        # ì¡°ê±´ë¬¸ ìˆ˜ì •
        if "ê²½ìŸì‚¬ ì •ë³´" in user_input:
            # ê²½ìŸì‚¬ ì •ë³´ ë°˜í™˜
            data_source = COMPETITOR_DATA
        elif "ì‹œì¥ ì •ë³´" in user_input:
            # ì‹œì¥ ì •ë³´ ë°˜í™˜
            data_source = MARKET_DATA
        elif "ê¸°ìˆ  ë™í–¥" in user_input:
            # ê¸°ìˆ  ë™í–¥ ë°˜í™˜
            data_source = TECH_DATA
        else:
            data_source = None

        if data_source is not None:
            response = "\n".join(
                [
                    f"[ê¸°ì‚¬ ì œëª©] {item['title']}\nì¼ì: {item['date']}\n* ìš”ì•½\n" + "\n".join(f"- {summary}" for summary in item['summary']) + f"\nì¶œì²˜: {item['source']}\n"
                    for item in data_source
                ]
            )
        else:
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            if session_history.messages:
                previous_messages = [{"role": msg['role'], "content": msg['content']} for msg in session_history.messages]
                response = chat_with_agent(user_input + "\n\nPrevious Messages: " + str(previous_messages), agent_executor)
            else:
                response = chat_with_agent(user_input, agent_executor)

        # ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
        st.session_state["messages"].append({"role": "user", "content": user_input})
        st.session_state["messages"].append({"role": "assistant", "content": response})

        # ì„¸ì…˜ ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€
        session_history.add_message({"role": "user", "content": user_input})
        session_history.add_message({"role": "assistant", "content": response})


    # ëŒ€í™” ë‚´ìš© ì¶œë ¥
    print_messages()

if __name__ == "__main__":
    main()
